# -*- coding: utf-8 -*-

import os
import re
import base64

from google.cloud import storage
from google.cloud import speech_v1p1beta1 as speech
from google.oauth2 import service_account

import openai
import cv2

from typing import List, Dict
from pytube import YouTube
from dataclasses import dataclass

from service.mongo import MongoORM
from service.enums import VideoPreprocessStatus


#
# Utils
#

def sanitize_filename(filename: str) -> str:
    filename = re.sub(r'[\/:*?"<>|]', '', filename)
    return filename

def split_text_into_sections(text: str, max_tokens: int = 7500) -> List[str]:
    """
    Split text into sections of max_tokens length

    Args:
        text (str): text to split
        max_tokens (int, optional): max length of each section. Defaults to 7500.

    Returns:
        List[str]: list of sections
    """
    lemmas = text.split(" ")
    sections = []
    current_section = ""

    for lemma in lemmas:
        current_section += (lemma + " ")
        if len(current_section) >= max_tokens:
            sections.append(current_section)
            current_section = ""

    if not len(current_section):
        return [text]

    return sections

def extract_frames(video_path: str, output_directory: str, timestamps: List[float], target_size: tuple):
    """
    Extract frames from video

    Args:
        video_path (str): path to video
        output_directory (str): path to output directory
        timestamps (List[float]): timestamps in seconds to extract
        target_size (tuple): target size of frame
    """
    video = cv2.VideoCapture(video_path)
    count = 0

    timestamps_ms = [int(timestamp * 1000) for timestamp in timestamps]

    while video.isOpened():
        ret, frame = video.read()

        if not ret:
            break

        current_timestamp = video.get(cv2.CAP_PROP_POS_MSEC)

        if int(current_timestamp) in timestamps_ms:
            resized_frame = cv2.resize(frame, target_size)
            output_path = f"frame_{count}.jpg"
            cv2.imwrite(output_path, resized_frame, [cv2.IMWRITE_JPEG_QUALITY, 90])
            count += 1

    video.release()


@dataclass
class PipelineParams:
    INTERSECTION_THRESHOLD: float = 0.0
    SECTION_SIZE: int = 7500


class Video2ArticlePipeline:

    def __init__(
            self,
            youtube_link: str,
            json_key_path: str,
            openai_api_key: str,
            params: PipelineParams = PipelineParams()
        ):
        """
        Video to article pipeline

        Args:
            youtube_link (str): = youtube link
            json_key_path (str): path to json key file for google cloud
            openai_api_key (str): openai api key
        """

        self.link = youtube_link
        self.params = params

        self._video_id = None
        self._orm: MongoORM = None

        credentials = service_account.Credentials.from_service_account_file(json_key_path)
        self.speech2text_storage = storage.Client(credentials=credentials)

        openai.api_key = openai_api_key
    
    def download_audio(self) -> str:
        """
        Download audio from youtube video

        Returns:
            str: path to downloaded audio file (generated by name of video)
        """
        youtube = YouTube(self.link)
        video = youtube.streams.filter(only_audio=True).first()
        audio_stream = video.download()
        audio_file = sanitize_filename(video.title) + ".mp3"
        os.rename(audio_stream, audio_file)
        return audio_file

    def download_video(self):
        """
        Download video from youtube

        Returns:
            str: path to downloaded audio file (generated by name of video)
        """
        yt = YouTube(self.link)
        video = yt.streams.get_highest_resolution()
        video_stream = video.download()
        video_file = sanitize_filename(video.title) + ".mp4"
        os.rename(video_stream, video_file)
        return video_file

    def transcribe_audio(self, audio_file: str) -> str:
        """
        Transcribe audio file to text using Google Cloud Speech-to-Text

        Args:
            audio_file (str): path to audio file
        
        Returns:
            str: text from audio file
        """

        # Connect to Google Cloud Storage
        storage_client = self.speech2text_storage 

        # Upload audio file to Google Cloud Storage
        bucket_name = "speech-to-text-qwerty"  
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob("audio.mp3")  
        blob.upload_from_filename(audio_file)

        # Create a new Speech Client
        audio_uri = f"gs://{bucket_name}/{blob.name}"
        client = speech.SpeechClient()

        # Create a long running operation
        audio = speech.RecognitionAudio(uri=audio_uri)

        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.MP3,
            sample_rate_hertz=16000,
            language_code='ru-RU',
            enable_word_time_offsets=True,
        )

        # Speech to text
        operation = client.long_running_recognize(config=config, audio=audio)
        response = operation.result()

        transcript = ""
        for result in response.results:
            for word_info in result.alternatives[0].words:
                word = word_info.word
                start_time = word_info.start_time.total_seconds()
                transcript += f'{word}({int(start_time//60)}:{int(start_time%60)}) '

        return transcript

    def gpt_prompt(self, text: str) -> str:
        """
        GPT-3 text update

        Args:
            text (str): raw text

        Returns:
            str: updated text
        """
        start_prompt = """
        Нужно разделить по смысловым частям текст из видео, который я вставлю ниже, и разделить на абзацы - миниумум 1 минута на каждый абзац, но можно и больше. В каждой из них должны быть:
        1. Заголовок, отображающий суть абзаца
        2. Пересказ этого абзаца с сохранением лица в тексте
        3. В начале каждой части поставь тайм код начала этого абзаца на основе меток времени слов в круглых скобках ().
        Каждый абзац должен быть в формате:
        {'title': 'Заголовок', 'text': 'краткое сокращение этой части', 'timecode': '1:10'}

        Кроме абзацев в формате выше ничего присылать не нужно
        """

        sections = split_text_into_sections(text=text, max_tokens=self.params.SECTION_SIZE)

        results = []
        prev_section = None
        for section in sections:
            # take 10% of the previous section and full of the current section
            if prev_section is not None:
                content = start_prompt + '\n' +\
                            prev_section[-int(len(prev_section) * self.params.INTERSECTION_THRESHOLD):] + '\n' + section
            else:
                content = start_prompt + section
                prev_section = section

            response = openai.ChatCompletion.create(
                model="gpt-3.5-turbo-16k",
                messages=[
                    {"role": "system", "content": "You are a helpful assistant."},
                    {"role": "user", "content": content}
                ],
                max_tokens=6000,
                temperature=0.5,
                top_p=0.2,
                stop=None,
            )
            results.append(response.choices[0].message.content.strip())
        return '\n'.join(results)

    def text_to_data(self, text: str) -> List[Dict[str, str]]:
        pattern = r"\{.*?\}"
        matches = re.findall(pattern, text, re.DOTALL)

        result = []

        for match in matches:
            try:
                result.append(eval(match))
            except SyntaxError:
                pass
        return result

    def add_images(self, video: str, data: List[Dict[str, str]]) -> List[Dict[str, str]]:
        timecodes = []
        for time in data:
            timecode = time['timecode'].split(':')
            timecode_final = int(timecode[0]) * 60 + int(timecode[1]) + 3
            timecodes.append(timecode_final)

        extract_frames(video_path=video, output_directory='',
                       timestamps=timecodes, target_size=(1980, 1080))

        count = 0
        for elem in data:
            try:
                with open(f'frame_{count}.jpg', 'rb') as f:
                    elem['image'] = str(base64.b64encode(f.read()))
                if count > 0:
                    os.remove(f'frame_{count}.jpg')
            except FileNotFoundError:
                with open(f'frame_0.jpg', 'rb') as f:
                    elem['image'] = str(base64.b64encode(f.read()))
            count += 1

        os.remove(f'frame_0.jpg')
        return data

    def run(self) -> List[Dict[str, str]]:
        """
        Run pipeline
        """
        audio = self.download_audio()
        video = self.download_video()
        text = self.transcribe_audio(audio)
        prep_text = self.gpt_prompt(text)
        result = self.text_to_data(prep_text)
        result = self.add_images(video, result)
        self._orm.update_video(video_id=self._video_id, ready_message=result, status=VideoPreprocessStatus.FINISHED)
        return result
